server:
  port: 8093
  servlet:
    context-path: /agent-station

# 线程池配置
thread:
  pool:
    executor:
      config:
        core-pool-size: 20
        max-pool-size: 50
        keep-alive-time: 5000
        block-queue-size: 5000
        policy: CallerRunsPolicy

spring:
  main:
    allow-bean-definition-overriding: true
  datasource:
    username: root
    password: rootroot
    url: jdbc:mysql://szhuima.dev:13306/agent-station?useUnicode=true&characterEncoding=utf8&autoReconnect=true&zeroDateTimeBehavior=convertToNull&serverTimezone=Asia/Shanghai&useSSL=true
    driver-class-name: com.mysql.cj.jdbc.Driver
    hikari:
      maximum-pool-size: 10
      minimum-idle: 5
      idle-timeout: 30000
      connection-timeout: 30000
      max-lifetime: 1800000
      validation-timeout: 3000
      connection-test-query: SELECT 1
  ai:
    openai:
      base-url: https://apis.itedus.cn
      api-key: sk-DVlmRyJNon9wqeni9eFa1fD7FcB1480fB8EfC4C126A85176
    ollama:
      base-url: http://192.168.1.3:11434
      embedding:
        model: nomic-embed-text
    vectorstore:
      pgvector:
        datasource:
          driver-class-name: org.postgresql.Driver
          username: postgres
          password: postgres
          url: jdbc:postgresql://szhuima.dev:5432/springai
          type: com.zaxxer.hikari.HikariDataSource
          hikari:
            maximum-pool-size: 5
            minimum-idle: 2
            idle-timeout: 30000
            connection-timeout: 30000


mybatis-plus:
  mapper-locations: classpath*:/mapper/**/*.xml
  type-aliases-package: dev.szhuima.agent.infrastructure.po
  global-config:
    db-config:
      # 主键类型（0: AUTO, 1: INPUT, 2: ID_WORKER, 3: UUID）
      id-type: auto
  configuration:
    map-underscore-to-camel-case: true
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl



#  ai:
#    mcp:
#      client:
#        enabled: true
#        request-timeout: 6000
#        sse:
#          connections:
#            server:
#              url: http://szhuima.dev:8081
logging:
  level:
    root: info

xfg:
  wrench:
    task:
      job:
        pool-size: 5
        thread-name-prefix: "job-search-scheduler-"
        wait-for-tasks-to-complete-on-shutdown: true
        await-termination-seconds: 30
        refresh-interval: 60000
        clean-invalid-tasks-cron: "0 0/5 * * * ?"


agent-station:
  rag:
    query-rewrite-model-id: 5
  workflow:
    dsl-path: /data/workflow




